{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "zRaiI3DLnISA",
        "outputId": "88eda6d6-62d9-4c33-f23e-536e6045a3bf"
      },
      "source": [
        "from google.colab import files\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ca7cf266-006a-40b5-9df6-77b19d3d851b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ca7cf266-006a-40b5-9df6-77b19d3d851b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train.csv to train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuKJplNYF1J1"
      },
      "source": [
        "from matplotlib.pyplot import plot, xlabel, ylabel\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from numpy import max\r\n",
        "from numpy import *\r\n",
        "from numpy.random import randn\r\n",
        "from pandas import crosstab, read_csv, Series\r\n",
        "import pickle"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDmtlG9z04H0"
      },
      "source": [
        "class Activation:\r\n",
        "    def __init__(self):\r\n",
        "        self.type = 'activation'\r\n",
        "        self.Z = 0\r\n",
        "\r\n",
        "    def forward(self, z):\r\n",
        "        pass\r\n",
        "\r\n",
        "    def backward(self, grad):\r\n",
        "        pass\r\n",
        "\r\n",
        "\r\n",
        "class Relu(Activation):\r\n",
        "    def forward(self, z):\r\n",
        "        self.Z = z\r\n",
        "        return where(z < 0, 0, z)\r\n",
        "\r\n",
        "    def backward(self, grad):\r\n",
        "        return where(self.Z < 0, 0, grad)\r\n",
        "\r\n",
        "    def getParams(self):\r\n",
        "        return []\r\n",
        "\r\n",
        "\r\n",
        "class Model:\r\n",
        "    def __init__(self):\r\n",
        "        self.layers = []  # list of instances of all layers of the network\r\n",
        "        self.parameters = []  # list of parameters of all linear layers of the network\r\n",
        "\r\n",
        "    # Adding the passed layer to our network\r\n",
        "    def add(self, layer):\r\n",
        "        self.layers.append(layer)  # The actual addition of the instant to the list of instances\r\n",
        "        if isinstance(layer, Linear):\r\n",
        "            self.parameters += layer.getParams()  # Calling the getParams() function of specific passed layer\r\n",
        "        # It is to concatenate all parameters of all layers in one list of parameters\r\n",
        "\r\n",
        "    def saveModel(self):\r\n",
        "        with open(\"model.pickle\", \"wb\") as f:\r\n",
        "            pickle.dump(self, f)\r\n",
        "\r\n",
        "    def loadModel(self):\r\n",
        "        pickleIn = open(\"model.pickle\", \"rb\")\r\n",
        "        modelLoaded = pickle.load(pickleIn)\r\n",
        "        return modelLoaded\r\n",
        "\r\n",
        "    # BatchPredictions = [] list of all outputs\r\n",
        "    BatchPredictions = []\r\n",
        "\r\n",
        "    def train(self, X, Y, batchSize, epochs, optimizer, lossFn, mode):\r\n",
        "        # mode = 0: first time training, mode = 1: train using previous results\r\n",
        "        if mode == 1:\r\n",
        "            # load model\r\n",
        "            var = self.loadModel()\r\n",
        "            self.layers = var.layers\r\n",
        "            self.parameters = var.parameters\r\n",
        "\r\n",
        "        \r\n",
        "\r\n",
        "\r\n",
        "        # Calculating the number of batches :\r\n",
        "        numBatches = int(ceil(X.shape[0] / batchSize))\r\n",
        "        # looping over the overall dataset one by one :\r\n",
        "        LossHistory = []\r\n",
        "        for epoch in range(epochs):\r\n",
        "            # BatchPredictions = [] list of all outputs\r\n",
        "            BatchPredictions = []\r\n",
        "            # Initialize a counter over all batches :\r\n",
        "            BatchesCounter = 0\r\n",
        "            # For accumulating the batch losses :\r\n",
        "            batchLossAcc = 0\r\n",
        "            # Looping over all batches one by one :\r\n",
        "            while BatchesCounter < numBatches:\r\n",
        "                # Generating the batch data :\r\n",
        "                # X [firstRowInBatch : LastRowInBatch]\r\n",
        "                XBatch = X[BatchesCounter * batchSize: (BatchesCounter + 1) * batchSize]\r\n",
        "                YBatch = Y[BatchesCounter * batchSize: (BatchesCounter + 1) * batchSize]\r\n",
        "\r\n",
        "                # Zeroing Gradients before each batch :\r\n",
        "                for p in self.parameters:\r\n",
        "                    p.grad = zeros_like(p.grad)\r\n",
        "\r\n",
        "                # Forward propagation :\r\n",
        "                # The for loop recursively computes the forward propagation , the output of a\r\n",
        "                # layer is put again as X to be input to the next layer :\r\n",
        "                for layer in self.layers:\r\n",
        "                    XBatch = layer.forward(XBatch)\r\n",
        "                    # The final XBatch is (batch_size, number Of Nodes Of LastLayer)\r\n",
        "\r\n",
        "                # BatchPredictions = A2.append [XBatch]\r\n",
        "                BatchPredictions.extend(XBatch.tolist())  # output predictions values\r\n",
        "\r\n",
        "                # Calculating the batch loss :\r\n",
        "                # The total loss of the current batch :\r\n",
        "                batchLoss = lossFn.forward(XBatch, YBatch)\r\n",
        "                # print (\"\\nLoss of batch \" ,BatchesCounter,\"is : \", batchLoss, \"\\n\")\r\n",
        "                # Accumulating the batch loss :\r\n",
        "                batchLossAcc += batchLoss\r\n",
        "\r\n",
        "                # Backward propagation :\r\n",
        "                grad = lossFn.backward(XBatch)  # This grad is of shape (batchSize, number Of Nodes Of LastLayer)\r\n",
        "                for i, layer in enumerate(self.layers[::-1]):  # [::-1] is to start from the last layer till the first layer\r\n",
        "                    grad = layer.backward(grad)  # model.layers = [Z1, A1, Z2, A2]    [W1, B1, W2, B2]\r\n",
        "                    if isinstance(layer, Linear):\r\n",
        "                        self.parameters[len(self.layers) - i - 1].grad = layer.W.grad\r\n",
        "                        self.parameters[len(self.layers) - i].grad = layer.b.grad\r\n",
        "\r\n",
        "                # for layer in self.layers[::-1]:  # [::-1] is to start from the last layer till the first layer\r\n",
        "                #     grad = layer.backward(grad)  # model.layers = [Z1, A1, Z2, A2]\r\n",
        "\r\n",
        "                # Updating parameters\r\n",
        "                optimizer.parameters = self.parameters\r\n",
        "                optimizer.update()\r\n",
        "                self.parameters = optimizer.parameters\r\n",
        "\r\n",
        "                # Increment the number of the batch for the next batch\r\n",
        "                BatchesCounter += 1\r\n",
        "\r\n",
        "            # function to get maximum prediction output of each (example)row  in each iteration\r\n",
        "\r\n",
        "            def function(x):\r\n",
        "                return argmax(x)\r\n",
        "\r\n",
        "            ypred = apply_along_axis(function, 1, BatchPredictions)\r\n",
        "\r\n",
        "            # Calculating the epoch loss :\r\n",
        "            epochLoss = batchLossAcc / numBatches\r\n",
        "            print(\"The loss of epoch \", epoch, \"is : \", epochLoss)\r\n",
        "\r\n",
        "            LossHistory.append(epochLoss)\r\n",
        "\r\n",
        "            # accuracy\r\n",
        "            Metric = EvaluationMetrics()\r\n",
        "            acc = Metric.accuracy(Y, ypred)\r\n",
        "            print(\"\\n The accuracy of epoch \", epoch, \"is : \", acc, \"%\\n\")\r\n",
        "            conf = Metric.confusionMatrix(Y, ypred)\r\n",
        "            print(\"\\n The confusion matrix of epoch \", epoch, \"is : \\n\", conf, \"\\n\")\r\n",
        "            precision = Metric.precision(conf)\r\n",
        "            print(\"\\n The precision of epoch \", epoch, \"is : \", precision, \"\\n\")\r\n",
        "            recall = Metric.recall(conf)\r\n",
        "            print(\"\\n The recall of epoch \", epoch, \"is : \", recall, \"\\n\")\r\n",
        "            f1Score = Metric.f1Score(conf)\r\n",
        "            print(\"\\n The f1Score of epoch \", epoch, \"is : \", f1Score, \"\\n\")\r\n",
        "            print(\"------------------------------------------------------------\\n\")\r\n",
        "\r\n",
        "            # print(self.parameters[1].data)\r\n",
        "            # print(\"grad\")\r\n",
        "            # print(self.parameters[1].grad)\r\n",
        "\r\n",
        "        # end of for loop\r\n",
        "        epochsList = range(epochs)\r\n",
        "        plot(epochsList, LossHistory)\r\n",
        "        xlabel('Epochs')\r\n",
        "        ylabel('Epoch Loss')\r\n",
        "        plt.show()\r\n",
        "        self.saveModel()\r\n",
        "\r\n",
        "    def evaluate(self, data, labels):\r\n",
        "        def function(x):\r\n",
        "            return argmax(x)\r\n",
        "\r\n",
        "        X = data\r\n",
        "        for layer in self.layers:\r\n",
        "            X = layer.forward(X)\r\n",
        "\r\n",
        "        ypred = apply_along_axis(function, 1, X)\r\n",
        "        accuracy = (sum(ypred == labels) / len(labels)) * 100\r\n",
        "        print('Validation Accuracy: ' + str(accuracy) + '\\n')\r\n",
        "\r\n",
        "\r\n",
        "# Creating multi dimension arrays of shape (number of nodes of previous layer, number of nodes of current layer)\r\n",
        "class CreateDataAndGrad:\r\n",
        "    def __init__(self, shape):\r\n",
        "        # Defining the shape of weights and biases\r\n",
        "        self.data = ndarray(shape, float32)\r\n",
        "        # Defining the shape of the gradient of weights and biases\r\n",
        "        self.grad = ndarray(shape, float32)\r\n",
        "\r\n",
        "    # In[7]:\r\n",
        "\r\n",
        "\r\n",
        "class Linear:  # It is the linear part of every layer #was class Linear(Function):\r\n",
        "    def __init__(self, prevNodes, currNodes):  # flag i\r\n",
        "        # Create weights and their data and gradient attributes\r\n",
        "        self.W = CreateDataAndGrad((prevNodes, currNodes))\r\n",
        "        # Initializing the data of the weights\r\n",
        "        self.W.data = 0.01 * randn(self.W.data.shape[0], self.W.data.shape[1])\r\n",
        "        # Create weights and their data and gradient attributes\r\n",
        "\r\n",
        "        # Create weights and their data and gradient attributes\r\n",
        "        self.b = CreateDataAndGrad((1, currNodes))\r\n",
        "        # Initializing the data of the bias\r\n",
        "        self.b.data = zeros_like(self.b.data)\r\n",
        "\r\n",
        "    def forward(self, X):  # Here self is a layer   f.forward(X) f--> Z1\r\n",
        "        # Implementing Z = X*W +b\r\n",
        "        self.Z = dot(X, self.W.data) + self.b.data\r\n",
        "        # Z will be of shape (number of instances in batch, number of nodes of current layer)\r\n",
        "        self.input = X  # Storing the input to each layer \"X\" as this is needed to compute the gradients of W in\r\n",
        "        # the backward function.\r\n",
        "        return self.Z\r\n",
        "\r\n",
        "    def backward(self, dL_dZ):\r\n",
        "        # Gradient of W :\r\n",
        "        self.dZ_dW = self.input.T\r\n",
        "        self.dL_dW = dot(self.dZ_dW, dL_dZ)  # dL/dW (for all samples) = (dL/dZ)*(dZ/dW)\r\n",
        "        self.W.grad += self.dL_dW  # Accumulating on the W gradient  #delta\r\n",
        "        # Gradient of b :\r\n",
        "        self.dL_db = sum(dL_dZ, axis=0, keepdims=True)  # dL/db (for all samples) = dL/dZ * dZ/db where dZ/db=1\r\n",
        "        self.b.grad += self.dL_db  # Accumulating on the W gradient\r\n",
        "        # Computing dZn/dAn-1 : (ex : dZ2/dA1)\r\n",
        "        dZ_dA = self.W.data.T\r\n",
        "        dL_dA = dot(dL_dZ, dZ_dA)  # dL/dA = (dL/dZ)*(dZ_dA)\r\n",
        "        return dL_dA\r\n",
        "\r\n",
        "    def getParams(self):  # It is to provide access to the parameters of a specific layer (here is the linear layer)\r\n",
        "        return [self.W, self.b]  # it is list of two arrays as : [array([[..],...,[...]]),array([[...]])]\r\n",
        "\r\n",
        "\r\n",
        "class SGD:\r\n",
        "    def __init__(self, parameters, alpha=0.001):\r\n",
        "        self.parameters = parameters\r\n",
        "        self.alpha = alpha\r\n",
        "\r\n",
        "    def update(self):\r\n",
        "        for p in self.parameters:\r\n",
        "            p.data = p.data - self.alpha * p.grad  # update parameters\r\n",
        "\r\n",
        "\r\n",
        "class MSE:\r\n",
        "    def forward(self, YHat, Y):\r\n",
        "        self.Y = Y\r\n",
        "        self.Y = reshape(self.Y, (len(self.Y), -1))\r\n",
        "        self.sqr = square(self.Y - YHat)\r\n",
        "        self.sum = sum(self.sqr, axis=0)\r\n",
        "        self.mse = 1 / (2 * len(self.Y)) * self.sum  # list of mse of each node\r\n",
        "        self.mean = self.mse.mean()  # The mean of all mse of the nodes\r\n",
        "        return self.mean\r\n",
        "\r\n",
        "    def backward(self, YHat):\r\n",
        "        self.dL_dYHat = YHat - self.Y  # dL/dA2\r\n",
        "        return self.dL_dYHat\r\n",
        "\r\n",
        "    # In[11]:\r\n",
        "\r\n",
        "\r\n",
        "class Multinomial:  # deal with as a loss function\r\n",
        "    def forward(self, YHat, Y):\r\n",
        "        exponent = exp(YHat - max(YHat, axis=1, keepdims=True))\r\n",
        "        self.multinomial = exponent / sum(exponent, axis=1, keepdims=True)\r\n",
        "        self.Y = Y\r\n",
        "        loss = - log(self.multinomial[range(len(Y)), Y])  # loss is of shape (1, Y[0])\r\n",
        "        return loss.mean()\r\n",
        "\r\n",
        "    def backward(self, YHat):\r\n",
        "        dL_dYHat = self.multinomial\r\n",
        "        dL_dYHat[range(len(self.Y)), self.Y] -= 1.0\r\n",
        "        dL_dYHat /= len(self.Y)\r\n",
        "        return dL_dYHat  # shape (number of examples , number of nodes of output layer)\r\n",
        "\r\n",
        "\r\n",
        "class EvaluationMetrics:\r\n",
        "    def accuracy(self, Y, ypred):\r\n",
        "        accur = (sum(ypred == Y) / len(Y)) * 100\r\n",
        "        return accur\r\n",
        "\r\n",
        "    def confusionMatrix(self, Y, ypred):\r\n",
        "        ypred = ypred\r\n",
        "        Y = Y\r\n",
        "        Y = Series(Y, name='Actual')\r\n",
        "        ypred = Series(ypred, name='Predicted')\r\n",
        "        df_confusion = crosstab(Y, ypred)\r\n",
        "        return df_confusion\r\n",
        "\r\n",
        "    def precision(self, cm):\r\n",
        "        return diag(cm) / sum(cm, axis=0)\r\n",
        "\r\n",
        "    def recall(self, cm):\r\n",
        "        return diag(cm) / sum(cm, axis=1)\r\n",
        "\r\n",
        "    def f1Score(self, cm):\r\n",
        "        R = self.recall(cm)\r\n",
        "        P = self.precision(cm)\r\n",
        "        return (2 * P * R) / (P + R)\r\n",
        "\r\n",
        "\r\n",
        "def loadMnist(validationRatio):\r\n",
        "    # ReadData\r\n",
        "    # df = read_csv(io.StringIO(uploaded['train.csv'].decode('utf-8')))\r\n",
        "    df = read_csv('./train.csv')\r\n",
        "    # shuffle data\r\n",
        "    shuffuled_df = df.sample(frac=1)\r\n",
        "    X = shuffuled_df.drop(labels=['label'], axis=1).values\r\n",
        "    # flattenng\r\n",
        "    X = X/255\r\n",
        "    Y = shuffuled_df.label.values  # output (list)\r\n",
        "    testSetSize = int(len(X) * validationRatio)\r\n",
        "    X_test = X[:testSetSize]\r\n",
        "    Y_test = Y[:testSetSize]\r\n",
        "    X_train = X[testSetSize:]\r\n",
        "    Y_train = Y[testSetSize:]\r\n",
        "    return (X_train, Y_train), (X_test,Y_test)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1RyWmDoZGMxS",
        "outputId": "639cb0c2-b213-4aef-fb39-dedc95bcbc4a"
      },
      "source": [
        "model = Model()\r\n",
        "\r\n",
        "prevNodes = 784  # of the input layer (layer0)\r\n",
        "currNodes = 100  # of the layer1\r\n",
        "Z1 = Linear(prevNodes, currNodes)\r\n",
        "model.add(Z1)\r\n",
        "\r\n",
        "A1 = Relu()\r\n",
        "model.add(A1)\r\n",
        "\r\n",
        "currNodes = 10\r\n",
        "prevNodes = 100\r\n",
        "Z2 = Linear(prevNodes, currNodes)\r\n",
        "model.add(Z2)\r\n",
        "\r\n",
        "optimizer = SGD(model.parameters, alpha=1.0)\r\n",
        "# optimizer = MomentumOptimizer(model.parameters, alpha = 1.0, momentum = 0.9)\r\n",
        "# optimizer = AdaGrad(model.parameters, alpha = 1.0, epsilon = 10 ** -10)\r\n",
        "# optimizer = RMSProp(model.parameters, alpha = 1.0, decay_rate = 0.9, epsilon = 10 ** -10)\r\n",
        "\r\n",
        "lossFun = Multinomial()\r\n",
        "batchSize = 100\r\n",
        "epochs = 5\r\n",
        "\r\n",
        "(X_train, Y_train), (X_test, Y_test) = loadMnist(0.2)\r\n",
        "\r\n",
        "choice = input('0. first time\\n1. use previous\\n')\r\n",
        "if choice == '0':\r\n",
        "    model.train(X_train, Y_train, batchSize, epochs, optimizer, lossFun, 0)\r\n",
        "elif choice == '1':\r\n",
        "    model.train(X_train, Y_train, batchSize, epochs, optimizer, lossFun, 1)\r\n",
        "\r\n",
        "model.evaluate(X_test, Y_test)\r\n",
        "\r\n",
        "del model\r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0. first time\n",
            "1. use previous\n",
            "0\n",
            "The loss of epoch  0 is :  0.4680568618804908\n",
            "\n",
            " The accuracy of epoch  0 is :  84.88690476190476 %\n",
            "\n",
            "\n",
            " The confusion matrix of epoch  0 is : \n",
            " Predicted     0     1     2     3     4     5     6     7     8     9\n",
            "Actual                                                               \n",
            "0          3139     0    48    23     4    46    41    14    35    15\n",
            "1             1  3486    80    22     4     7     8     7    61    18\n",
            "2            48    59  2802    71    53     8    93    55    83    31\n",
            "3            44    29   137  2868     3   167    29    54   162    46\n",
            "4            11    18    64     8  2743     3    66    46    59   243\n",
            "5           115    36    49   161    34  2382    49    31   124    47\n",
            "6            43    20   111     9    38    36  2984     5    42    11\n",
            "7            35    47    89    24    38    11     8  3017    43   177\n",
            "8            33    98   115   161    36   139    34    42  2521   103\n",
            "9            30    19    46    53   245    32    12   211   112  2580 \n",
            "\n",
            "\n",
            " The precision of epoch  0 is :  Predicted\n",
            "0    0.897113\n",
            "1    0.914481\n",
            "2    0.791302\n",
            "3    0.843529\n",
            "4    0.857724\n",
            "5    0.841399\n",
            "6    0.897714\n",
            "7    0.866456\n",
            "8    0.777606\n",
            "9    0.788750\n",
            "dtype: float64 \n",
            "\n",
            "\n",
            " The recall of epoch  0 is :  Actual\n",
            "0    0.932838\n",
            "1    0.943692\n",
            "2    0.848320\n",
            "3    0.810398\n",
            "4    0.841153\n",
            "5    0.786658\n",
            "6    0.904517\n",
            "7    0.864718\n",
            "8    0.768129\n",
            "9    0.772455\n",
            "dtype: float64 \n",
            "\n",
            "\n",
            " The f1Score of epoch  0 is :  Predicted\n",
            "0    0.914627\n",
            "1    0.928857\n",
            "2    0.818819\n",
            "3    0.826632\n",
            "4    0.849357\n",
            "5    0.813108\n",
            "6    0.901102\n",
            "7    0.865586\n",
            "8    0.772839\n",
            "9    0.780517\n",
            "dtype: float64 \n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "The loss of epoch  1 is :  0.14992310958238472\n",
            "\n",
            " The accuracy of epoch  1 is :  95.41666666666667 %\n",
            "\n",
            "\n",
            " The confusion matrix of epoch  1 is : \n",
            " Predicted     0     1     2     3     4     5     6     7     8     9\n",
            "Actual                                                               \n",
            "0          3290     0     6     3     7     4    17     4    23    11\n",
            "1             0  3615    16     7     5     3     3     9    33     3\n",
            "2            13    17  3139    28    20     3    14    28    34     7\n",
            "3             7     7    38  3308     1    74     4    23    56    21\n",
            "4             6     6    15     2  3099     1    17     3    14    98\n",
            "5            14     3     3    60    11  2867    26     3    27    14\n",
            "6            18     5    13     2    12    22  3211     2    14     0\n",
            "7             7    15    33    14    11     2     1  3336     8    62\n",
            "8            14    30    20    45     9    29    15     9  3078    33\n",
            "9            13    10     3    30    65    15     0    57    30  3117 \n",
            "\n",
            "\n",
            " The precision of epoch  1 is :  Predicted\n",
            "0    0.972797\n",
            "1    0.974919\n",
            "2    0.955265\n",
            "3    0.945413\n",
            "4    0.956481\n",
            "5    0.949338\n",
            "6    0.970677\n",
            "7    0.960276\n",
            "8    0.927947\n",
            "9    0.926025\n",
            "dtype: float64 \n",
            "\n",
            "\n",
            " The recall of epoch  1 is :  Actual\n",
            "0    0.977712\n",
            "1    0.978614\n",
            "2    0.950348\n",
            "3    0.934727\n",
            "4    0.950322\n",
            "5    0.946830\n",
            "6    0.973325\n",
            "7    0.956148\n",
            "8    0.937843\n",
            "9    0.933234\n",
            "dtype: float64 \n",
            "\n",
            "\n",
            " The f1Score of epoch  1 is :  Predicted\n",
            "0    0.975248\n",
            "1    0.976763\n",
            "2    0.952800\n",
            "3    0.940040\n",
            "4    0.953392\n",
            "5    0.948082\n",
            "6    0.971999\n",
            "7    0.958208\n",
            "8    0.932869\n",
            "9    0.929615\n",
            "dtype: float64 \n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "The loss of epoch  2 is :  0.1058403661847659\n",
            "\n",
            " The accuracy of epoch  2 is :  96.7202380952381 %\n",
            "\n",
            "\n",
            " The confusion matrix of epoch  2 is : \n",
            " Predicted     0     1     2     3     4     5     6     7     8     9\n",
            "Actual                                                               \n",
            "0          3311     0     3     2     5     3    14     4    14     9\n",
            "1             0  3635    11     7     5     2     4     5    23     2\n",
            "2            11    12  3186    21    10     3     9    24    24     3\n",
            "3             4     4    30  3362     0    57     2    18    44    18\n",
            "4             2     5     7     0  3156     1    13     3     7    67\n",
            "5             8     3     2    34     6  2924    15     2    19    15\n",
            "6            10     3    11     0    12    15  3239     1     8     0\n",
            "7             6    13    23    10     6     2     1  3379     9    40\n",
            "8            12    21    14    31     7    23    12     6  3131    25\n",
            "9             8     6     2    28    48    14     0    38    21  3175 \n",
            "\n",
            "\n",
            " The precision of epoch  2 is :  Predicted\n",
            "0    0.981910\n",
            "1    0.981902\n",
            "2    0.968683\n",
            "3    0.961946\n",
            "4    0.969585\n",
            "5    0.960578\n",
            "6    0.978846\n",
            "7    0.970977\n",
            "8    0.948788\n",
            "9    0.946631\n",
            "dtype: float64 \n",
            "\n",
            "\n",
            " The recall of epoch  2 is :  Actual\n",
            "0    0.983952\n",
            "1    0.984028\n",
            "2    0.964578\n",
            "3    0.949986\n",
            "4    0.967801\n",
            "5    0.965654\n",
            "6    0.981813\n",
            "7    0.968472\n",
            "8    0.953991\n",
            "9    0.950599\n",
            "dtype: float64 \n",
            "\n",
            "\n",
            " The f1Score of epoch  2 is :  Predicted\n",
            "0    0.982930\n",
            "1    0.982964\n",
            "2    0.966626\n",
            "3    0.955928\n",
            "4    0.968692\n",
            "5    0.963109\n",
            "6    0.980327\n",
            "7    0.969723\n",
            "8    0.951383\n",
            "9    0.948611\n",
            "dtype: float64 \n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "The loss of epoch  3 is :  0.08146059234942322\n",
            "\n",
            " The accuracy of epoch  3 is :  97.45535714285715 %\n",
            "\n",
            "\n",
            " The confusion matrix of epoch  3 is : \n",
            " Predicted     0     1     2     3     4     5     6     7     8     9\n",
            "Actual                                                               \n",
            "0          3318     0     1     3     2     2    13     4    14     8\n",
            "1             0  3647     8     5     5     0     2     4    22     1\n",
            "2             8    12  3209    15     9     3     6    21    15     5\n",
            "3             4     4    22  3413     0    38     0    17    27    14\n",
            "4             3     7     7     0  3180     0     8     3     4    49\n",
            "5             6     2     3    25     3  2949    14     1    13    12\n",
            "6            11     4     9     0     8    15  3244     1     7     0\n",
            "7             4    13    21     9     5     1     2  3398     9    27\n",
            "8             8    20     9    17     5    15    12     4  3167    25\n",
            "9             7     4     2    17    32    12     1    27    18  3220 \n",
            "\n",
            "\n",
            " The precision of epoch  3 is :  Predicted\n",
            "0    0.984862\n",
            "1    0.982225\n",
            "2    0.975084\n",
            "3    0.974030\n",
            "4    0.978763\n",
            "5    0.971664\n",
            "6    0.982435\n",
            "7    0.976437\n",
            "8    0.960862\n",
            "9    0.958048\n",
            "dtype: float64 \n",
            "\n",
            "\n",
            " The recall of epoch  3 is :  Actual\n",
            "0    0.986033\n",
            "1    0.987277\n",
            "2    0.971541\n",
            "3    0.964397\n",
            "4    0.975161\n",
            "5    0.973910\n",
            "6    0.983328\n",
            "7    0.973918\n",
            "8    0.964960\n",
            "9    0.964072\n",
            "dtype: float64 \n",
            "\n",
            "\n",
            " The f1Score of epoch  3 is :  Predicted\n",
            "0    0.985447\n",
            "1    0.984744\n",
            "2    0.973309\n",
            "3    0.969189\n",
            "4    0.976959\n",
            "5    0.972786\n",
            "6    0.982881\n",
            "7    0.975176\n",
            "8    0.962907\n",
            "9    0.961051\n",
            "dtype: float64 \n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "The loss of epoch  4 is :  0.06321397077749304\n",
            "\n",
            " The accuracy of epoch  4 is :  98.06845238095238 %\n",
            "\n",
            "\n",
            " The confusion matrix of epoch  4 is : \n",
            " Predicted     0     1     2     3     4     5     6     7     8     9\n",
            "Actual                                                               \n",
            "0          3326     1     3     1     1     1    10     3    11     8\n",
            "1             0  3654    10     4     5     0     2     4    14     1\n",
            "2             6    11  3239    11     8     1     3    12     9     3\n",
            "3             3     3    15  3449     0    25     0     6    25    13\n",
            "4             2     3     4     0  3202     0     5     4     3    38\n",
            "5             4     2     1    22     1  2965    10     2    11    10\n",
            "6            11     2     4     1     7    10  3258     1     5     0\n",
            "7             3    10    15     4     2     1     1  3425     7    21\n",
            "8             5    15     8    15     4    14    11     5  3190    15\n",
            "9             6     3     1    15    25     9     0    24    14  3243 \n",
            "\n",
            "\n",
            " The precision of epoch  4 is :  Predicted\n",
            "0    0.988116\n",
            "1    0.986501\n",
            "2    0.981515\n",
            "3    0.979273\n",
            "4    0.983717\n",
            "5    0.979841\n",
            "6    0.987273\n",
            "7    0.982501\n",
            "8    0.969900\n",
            "9    0.967482\n",
            "dtype: float64 \n",
            "\n",
            "\n",
            " The recall of epoch  4 is :  Actual\n",
            "0    0.988410\n",
            "1    0.989172\n",
            "2    0.980624\n",
            "3    0.974569\n",
            "4    0.981907\n",
            "5    0.979194\n",
            "6    0.987572\n",
            "7    0.981657\n",
            "8    0.971968\n",
            "9    0.970958\n",
            "dtype: float64 \n",
            "\n",
            "\n",
            " The f1Score of epoch  4 is :  Predicted\n",
            "0    0.988263\n",
            "1    0.987835\n",
            "2    0.981069\n",
            "3    0.976915\n",
            "4    0.982812\n",
            "5    0.979518\n",
            "6    0.987422\n",
            "7    0.982079\n",
            "8    0.970933\n",
            "9    0.969217\n",
            "dtype: float64 \n",
            "\n",
            "------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 96.78571428571429\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
